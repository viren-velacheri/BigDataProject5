2022-04-14T17:54:23,683 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T17:54:23,683 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T17:54:23,721 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T17:54:23,721 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T17:54:23,867 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T17:54:23,867 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T17:54:23,882 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: vgg.mar
2022-04-14T17:54:23,882 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: vgg.mar
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T17:54:24,851 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T17:54:24,851 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T17:54:24,851 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T17:54:24,883 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T17:54:24,883 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T17:54:24,883 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T17:54:24,883 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T17:54:24,883 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T17:54:24,883 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T17:54:24,883 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T17:54:24,883 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T17:54:24,883 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T17:54:24,883 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T17:54:24,883 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T17:54:24,883 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T17:54:24,883 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T17:54:24,883 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T17:54:24,883 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T17:54:24,883 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T17:54:24,883 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T17:54:24,884 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T17:54:24,883 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T17:54:24,883 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T17:54:24,883 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T17:54:24,885 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T17:54:24,885 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T17:54:24,884 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T17:54:24,885 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T17:54:24,885 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T17:54:24,885 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T17:54:24,885 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T17:54:24,883 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T17:54:24,883 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T17:54:24,883 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T17:54:24,890 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T17:54:24,883 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T17:54:24,890 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T17:54:25,412 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T17:54:25,412 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T17:54:25,412 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T17:54:25,412 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T17:54:25,438 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T17:54:25,438 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T17:54:25,439 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T17:54:25,439 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T17:54:25,441 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T17:54:25,441 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T17:54:25,935 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T17:54:25,935 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T17:54:26,077 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,078 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2022-04-14T17:54:26,080 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - [PID]23963
2022-04-14T17:54:26,081 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,081 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,081 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,081 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,078 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2022-04-14T17:54:26,086 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - [PID]23966
2022-04-14T17:54:26,087 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,087 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,078 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365802764892578|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,087 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458137512207031|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,088 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,088 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:61871.4453125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,089 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1703.7421875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,089 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.8|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980466
2022-04-14T17:54:26,087 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,090 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,090 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T17:54:26,090 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T17:54:26,093 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T17:54:26,093 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T17:54:26,136 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2022-04-14T17:54:26,140 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - [PID]23962
2022-04-14T17:54:26,140 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,140 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,140 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,140 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,141 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T17:54:26,141 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T17:54:26,155 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2022-04-14T17:54:26,158 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2022-04-14T17:54:26,158 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2022-04-14T17:54:26,159 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2022-04-14T17:54:26,159 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - [PID]23979
2022-04-14T17:54:26,160 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,160 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,160 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T17:54:26,160 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T17:54:26,160 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,161 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,163 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466163
2022-04-14T17:54:26,163 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466163
2022-04-14T17:54:26,163 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466163
2022-04-14T17:54:26,163 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466163
2022-04-14T17:54:26,169 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466169
2022-04-14T17:54:26,169 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466169
2022-04-14T17:54:26,169 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-04-14T17:54:26,170 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2022-04-14T17:54:26,171 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - [PID]23973
2022-04-14T17:54:26,172 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - [PID]23983
2022-04-14T17:54:26,172 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,172 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,172 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,172 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,172 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,172 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,172 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,172 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T17:54:26,172 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T17:54:26,172 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,172 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T17:54:26,172 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T17:54:26,173 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2022-04-14T17:54:26,173 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466173
2022-04-14T17:54:26,173 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466173
2022-04-14T17:54:26,202 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-04-14T17:54:26,202 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466202
2022-04-14T17:54:26,202 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466202
2022-04-14T17:54:26,199 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2022-04-14T17:54:26,203 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - [PID]23964
2022-04-14T17:54:26,203 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,203 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,203 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,203 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,203 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T17:54:26,203 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T17:54:26,204 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466204
2022-04-14T17:54:26,204 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466204
2022-04-14T17:54:26,205 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2022-04-14T17:54:26,215 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466215
2022-04-14T17:54:26,215 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466215
2022-04-14T17:54:26,234 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2022-04-14T17:54:26,245 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2022-04-14T17:54:26,245 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2022-04-14T17:54:26,246 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - [PID]23980
2022-04-14T17:54:26,246 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - [PID]23977
2022-04-14T17:54:26,247 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,247 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,247 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,247 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,247 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T17:54:26,247 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,247 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T17:54:26,247 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,247 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T17:54:26,247 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,247 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,247 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T17:54:26,262 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2022-04-14T17:54:26,263 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,263 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - [PID]23981
2022-04-14T17:54:26,263 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,263 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,263 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,263 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T17:54:26,263 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T17:54:26,263 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,264 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,276 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2022-04-14T17:54:26,276 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,276 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,277 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,280 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,280 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-04-14T17:54:26,282 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - [PID]23976
2022-04-14T17:54:26,282 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,282 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,282 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,282 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,282 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,283 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T17:54:26,283 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T17:54:26,288 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466288
2022-04-14T17:54:26,288 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466288
2022-04-14T17:54:26,284 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2022-04-14T17:54:26,291 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466289
2022-04-14T17:54:26,301 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466301
2022-04-14T17:54:26,292 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - [PID]23961
2022-04-14T17:54:26,301 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466301
2022-04-14T17:54:26,301 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,301 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2022-04-14T17:54:26,301 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2022-04-14T17:54:26,301 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466301
2022-04-14T17:54:26,291 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466289
2022-04-14T17:54:26,301 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-04-14T17:54:26,301 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,301 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,302 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T17:54:26,302 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T17:54:26,302 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,302 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - [PID]23965
2022-04-14T17:54:26,302 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2022-04-14T17:54:26,302 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,301 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466301
2022-04-14T17:54:26,302 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - [PID]23974
2022-04-14T17:54:26,302 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,303 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,303 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T17:54:26,303 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,303 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,302 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,303 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,303 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T17:54:26,303 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T17:54:26,303 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,303 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T17:54:26,292 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2022-04-14T17:54:26,330 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,332 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466332
2022-04-14T17:54:26,332 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466332
2022-04-14T17:54:26,330 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,360 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466359
2022-04-14T17:54:26,330 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2022-04-14T17:54:26,359 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2022-04-14T17:54:26,360 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - [PID]23975
2022-04-14T17:54:26,360 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466360
2022-04-14T17:54:26,360 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466360
2022-04-14T17:54:26,330 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,360 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,360 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466359
2022-04-14T17:54:26,331 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2022-04-14T17:54:26,332 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2022-04-14T17:54:26,362 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,361 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,362 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,362 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - [PID]23978
2022-04-14T17:54:26,362 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,363 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T17:54:26,363 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T17:54:26,363 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T17:54:26,362 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2022-04-14T17:54:26,363 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T17:54:26,364 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,364 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T17:54:26,364 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T17:54:26,364 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T17:54:26,377 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,387 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2022-04-14T17:54:26,397 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466397
2022-04-14T17:54:26,401 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466401
2022-04-14T17:54:26,397 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466397
2022-04-14T17:54:26,401 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980466401
2022-04-14T17:54:26,397 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,396 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,396 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2022-04-14T17:54:26,431 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:26,433 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T17:54:28,486 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,497 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2217
2022-04-14T17:54:28,497 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2217
2022-04-14T17:54:28,499 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,499 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,499 [INFO ] W-9012-vgg_1.0 TS_METRICS - W-9012-vgg_1.0.ms:3634|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,500 [INFO ] W-9012-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,535 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,536 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2256
2022-04-14T17:54:28,536 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2256
2022-04-14T17:54:28,537 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,537 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,537 [INFO ] W-9013-vgg_1.0 TS_METRICS - W-9013-vgg_1.0.ms:3672|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,538 [INFO ] W-9013-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:119|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,561 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,571 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2308
2022-04-14T17:54:28,571 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2308
2022-04-14T17:54:28,571 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,571 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,572 [INFO ] W-9014-vgg_1.0 TS_METRICS - W-9014-vgg_1.0.ms:3706|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,572 [INFO ] W-9014-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:91|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,583 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,584 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2293
2022-04-14T17:54:28,584 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2293
2022-04-14T17:54:28,584 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,584 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,585 [INFO ] W-9004-vgg_1.0 TS_METRICS - W-9004-vgg_1.0.ms:3722|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,585 [INFO ] W-9004-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:77|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,593 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,595 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2318
2022-04-14T17:54:28,595 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2318
2022-04-14T17:54:28,595 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,595 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,595 [INFO ] W-9006-vgg_1.0 TS_METRICS - W-9006-vgg_1.0.ms:3733|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,596 [INFO ] W-9006-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:115|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,596 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,599 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,599 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2317
2022-04-14T17:54:28,599 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2317
2022-04-14T17:54:28,599 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,599 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,599 [INFO ] W-9009-vgg_1.0 TS_METRICS - W-9009-vgg_1.0.ms:3736|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,600 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2336
2022-04-14T17:54:28,600 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2336
2022-04-14T17:54:28,600 [INFO ] W-9009-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:113|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,600 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,600 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,600 [INFO ] W-9000-vgg_1.0 TS_METRICS - W-9000-vgg_1.0.ms:3741|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,600 [INFO ] W-9000-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:62|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,604 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,605 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2275
2022-04-14T17:54:28,605 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2275
2022-04-14T17:54:28,605 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,605 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,605 [INFO ] W-9015-vgg_1.0 TS_METRICS - W-9015-vgg_1.0.ms:3739|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,605 [INFO ] W-9015-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,608 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,608 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2278
2022-04-14T17:54:28,608 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2278
2022-04-14T17:54:28,609 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,609 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,609 [INFO ] W-9001-vgg_1.0 TS_METRICS - W-9001-vgg_1.0.ms:3748|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,609 [INFO ] W-9001-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,617 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,618 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2258
2022-04-14T17:54:28,618 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2258
2022-04-14T17:54:28,618 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,618 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,618 [INFO ] W-9008-vgg_1.0 TS_METRICS - W-9008-vgg_1.0.ms:3755|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,618 [INFO ] W-9008-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:59|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,618 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,619 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2271
2022-04-14T17:54:28,619 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2271
2022-04-14T17:54:28,619 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,619 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,619 [INFO ] W-9003-vgg_1.0 TS_METRICS - W-9003-vgg_1.0.ms:3758|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,619 [INFO ] W-9003-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:59|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,640 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,640 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263
2022-04-14T17:54:28,640 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263
2022-04-14T17:54:28,640 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,640 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,640 [INFO ] W-9007-vgg_1.0 TS_METRICS - W-9007-vgg_1.0.ms:3777|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,640 [INFO ] W-9007-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:45|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,661 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,662 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2265
2022-04-14T17:54:28,662 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2265
2022-04-14T17:54:28,662 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,662 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,662 [INFO ] W-9005-vgg_1.0 TS_METRICS - W-9005-vgg_1.0.ms:3800|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,663 [INFO ] W-9005-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:38|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,668 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,669 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2217
2022-04-14T17:54:28,669 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2217
2022-04-14T17:54:28,669 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,669 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,669 [INFO ] W-9002-vgg_1.0 TS_METRICS - W-9002-vgg_1.0.ms:3808|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,669 [INFO ] W-9002-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:51|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,679 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,679 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2223
2022-04-14T17:54:28,679 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2223
2022-04-14T17:54:28,679 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,679 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,679 [INFO ] W-9010-vgg_1.0 TS_METRICS - W-9010-vgg_1.0.ms:3815|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,679 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T17:54:28,679 [INFO ] W-9010-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:59|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:54:28,680 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2279
2022-04-14T17:54:28,680 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2279
2022-04-14T17:54:28,680 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,680 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T17:54:28,680 [INFO ] W-9011-vgg_1.0 TS_METRICS - W-9011-vgg_1.0.ms:3816|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980468
2022-04-14T17:54:28,680 [INFO ] W-9011-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:55:15,987 [INFO ] epollEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:60186 "GET /models HTTP/1.1" 200 11
2022-04-14T17:55:15,988 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T17:55:25,962 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365726470947266|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458213806152344|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,963 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60153.15625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,964 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3421.6171875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:55:25,964 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980525
2022-04-14T17:56:25,962 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365726470947266|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458213806152344|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,963 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,964 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60153.08984375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,964 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3421.6640625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:56:25,964 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980585
2022-04-14T17:57:25,966 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365726470947266|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458213806152344|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60153.12109375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3421.640625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:57:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980645
2022-04-14T17:58:25,964 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:14.3|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,964 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365718841552734|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,964 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458221435546875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,965 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60152.84375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,965 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3421.9140625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:58:25,965 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980705
2022-04-14T17:59:25,964 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365718841552734|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458221435546875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,965 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60157.0390625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,966 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3417.73046875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T17:59:25,966 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980765
2022-04-14T18:00:25,967 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365467071533203|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458473205566406|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,967 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60156.62109375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3418.15625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:25,968 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980825
2022-04-14T18:00:40,530 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980840530
2022-04-14T18:00:40,530 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649980840530
2022-04-14T18:00:40,532 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Backend received inference at: 1649980840
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 222, in handle
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     output = self.inference(data_preprocess)
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 175, in inference
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     results = self.model(marshalled_data, *args, **kwargs)
2022-04-14T18:00:40,706 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/tmp/models/164d2d92b2724530abbabc012b7bc584/model.py", line 45, in forward
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     y = self.fc1(y)
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 176
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 176
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -   File "/users/shaniyur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG -     return F.linear(input, self.weight, self.bias)
2022-04-14T18:00:40,707 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x25088 and 512x10)
2022-04-14T18:00:40,709 [INFO ] W-9012-vgg_1.0 ACCESS_LOG - /127.0.0.1:50926 "PUT /predictions/vgg HTTP/1.1" 503 187
2022-04-14T18:00:40,710 [INFO ] W-9012-vgg_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:00:40,710 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 330294, Inference time ns: 180740844
2022-04-14T18:00:40,710 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 330294, Inference time ns: 180740844
2022-04-14T18:00:40,710 [INFO ] W-9012-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:01:25,970 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:12.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,970 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365459442138672|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,970 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458480834960938|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,970 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60111.77734375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3462.9921875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:01:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980885
2022-04-14T18:02:25,970 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:12.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,970 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365447998046875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,970 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458492279052734|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,971 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60110.73046875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3464.05078125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:02:25,971 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649980945
2022-04-14T18:54:04,440 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T18:54:04,440 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T18:54:04,480 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T18:54:04,480 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T18:54:04,636 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414180242052-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T18:54:04,636 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414180242052-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T18:54:04,650 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414180242052-shutdown.cfg",
  "modelCount": 1,
  "created": 1649980962053,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T18:54:04,650 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414180242052-shutdown.cfg",
  "modelCount": 1,
  "created": 1649980962053,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T18:54:04,662 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414180242052-shutdown.cfg
2022-04-14T18:54:04,662 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414180242052-shutdown.cfg
2022-04-14T18:54:04,663 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414180242052-shutdown.cfg validated successfully
2022-04-14T18:54:04,663 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414180242052-shutdown.cfg validated successfully
2022-04-14T18:54:05,643 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T18:54:05,643 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:54:05,644 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T18:54:05,644 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T18:54:05,644 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T18:54:05,676 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T18:54:05,676 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T18:54:05,677 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T18:54:05,677 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T18:54:05,677 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T18:54:05,677 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T18:54:05,677 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T18:54:05,677 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T18:54:05,676 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T18:54:05,677 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T18:54:05,676 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T18:54:05,677 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T18:54:05,676 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T18:54:05,677 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T18:54:05,676 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T18:54:05,677 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T18:54:05,677 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T18:54:05,677 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T18:54:05,676 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T18:54:05,676 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T18:54:05,676 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T18:54:05,676 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T18:54:05,677 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T18:54:05,676 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T18:54:05,677 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T18:54:05,677 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T18:54:05,677 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T18:54:05,679 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T18:54:05,678 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T18:54:05,676 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T18:54:05,677 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T18:54:05,679 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T18:54:05,677 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T18:54:05,678 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T18:54:06,205 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T18:54:06,205 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T18:54:06,205 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T18:54:06,205 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T18:54:06,211 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T18:54:06,211 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T18:54:06,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T18:54:06,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T18:54:06,214 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T18:54:06,214 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T18:54:06,830 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T18:54:06,830 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T18:54:06,844 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2022-04-14T18:54:06,846 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - [PID]24853
2022-04-14T18:54:06,846 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,847 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,847 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,847 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,863 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T18:54:06,863 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T18:54:06,885 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2022-04-14T18:54:06,865 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2022-04-14T18:54:06,896 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - [PID]24854
2022-04-14T18:54:06,897 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,897 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,897 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,897 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T18:54:06,897 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T18:54:06,899 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,896 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - [PID]24855
2022-04-14T18:54:06,900 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,900 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,900 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T18:54:06,900 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T18:54:06,900 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,901 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,924 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2022-04-14T18:54:06,926 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - [PID]24856
2022-04-14T18:54:06,926 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,926 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,926 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,927 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,927 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T18:54:06,927 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T18:54:06,954 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,955 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365413665771484|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,955 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2022-04-14T18:54:06,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458526611328125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,957 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:61815.51171875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1759.2734375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.9|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984046
2022-04-14T18:54:06,958 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-04-14T18:54:06,959 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2022-04-14T18:54:06,961 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - [PID]24865
2022-04-14T18:54:06,961 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2022-04-14T18:54:06,962 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,962 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,961 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - [PID]24862
2022-04-14T18:54:06,961 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2022-04-14T18:54:06,962 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,962 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,962 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,962 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T18:54:06,962 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,962 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T18:54:06,962 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,962 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T18:54:06,962 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T18:54:06,962 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,964 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2022-04-14T18:54:06,968 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-04-14T18:54:06,976 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,976 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,976 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,976 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,977 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046977
2022-04-14T18:54:06,977 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046977
2022-04-14T18:54:06,977 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046977
2022-04-14T18:54:06,976 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,977 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2022-04-14T18:54:06,982 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2022-04-14T18:54:06,977 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046977
2022-04-14T18:54:06,982 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2022-04-14T18:54:06,983 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - [PID]24867
2022-04-14T18:54:06,983 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - [PID]24859
2022-04-14T18:54:06,983 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,983 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,982 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046982
2022-04-14T18:54:06,983 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,983 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,983 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,984 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T18:54:06,984 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T18:54:06,984 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T18:54:06,984 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T18:54:06,984 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,976 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046976
2022-04-14T18:54:06,983 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,982 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046982
2022-04-14T18:54:06,985 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,986 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2022-04-14T18:54:06,989 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046989
2022-04-14T18:54:06,988 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - [PID]24858
2022-04-14T18:54:06,989 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046989
2022-04-14T18:54:06,990 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,990 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2022-04-14T18:54:06,990 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:06,990 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:06,990 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:06,990 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2022-04-14T18:54:06,990 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T18:54:06,991 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046990
2022-04-14T18:54:06,990 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T18:54:06,991 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046990
2022-04-14T18:54:06,993 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046993
2022-04-14T18:54:06,993 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984046993
2022-04-14T18:54:06,993 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2022-04-14T18:54:07,011 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2022-04-14T18:54:07,012 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - [PID]24857
2022-04-14T18:54:07,013 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,013 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,013 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,013 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,013 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T18:54:07,013 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T18:54:07,012 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2022-04-14T18:54:07,014 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - [PID]24866
2022-04-14T18:54:07,014 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,014 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,014 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,014 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,015 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T18:54:07,015 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T18:54:07,018 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047018
2022-04-14T18:54:07,018 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047018
2022-04-14T18:54:07,020 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2022-04-14T18:54:07,068 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047068
2022-04-14T18:54:07,068 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2022-04-14T18:54:07,068 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047068
2022-04-14T18:54:07,054 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-04-14T18:54:07,054 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2022-04-14T18:54:07,069 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - [PID]24860
2022-04-14T18:54:07,069 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - [PID]24863
2022-04-14T18:54:07,069 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2022-04-14T18:54:07,069 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,068 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2022-04-14T18:54:07,069 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - [PID]24852
2022-04-14T18:54:07,069 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,081 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - [PID]24861
2022-04-14T18:54:07,081 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,054 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2022-04-14T18:54:07,081 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,081 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,069 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,081 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - [PID]24864
2022-04-14T18:54:07,081 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,081 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,082 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T18:54:07,082 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T18:54:07,081 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,081 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,082 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,082 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T18:54:07,082 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T18:54:07,082 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:54:07,082 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,082 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T18:54:07,082 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:54:07,082 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T18:54:07,082 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:54:07,082 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T18:54:07,082 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T18:54:07,083 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T18:54:07,083 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T18:54:07,106 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,106 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,106 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,107 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047107
2022-04-14T18:54:07,107 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047107
2022-04-14T18:54:07,112 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2022-04-14T18:54:07,112 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,112 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,112 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,114 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,120 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,120 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2022-04-14T18:54:07,122 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2022-04-14T18:54:07,122 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047122
2022-04-14T18:54:07,122 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047122
2022-04-14T18:54:07,124 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,125 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047125
2022-04-14T18:54:07,125 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,125 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047125
2022-04-14T18:54:07,125 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2022-04-14T18:54:07,125 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047125
2022-04-14T18:54:07,125 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047125
2022-04-14T18:54:07,137 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,132 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047132
2022-04-14T18:54:07,126 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-04-14T18:54:07,132 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984047132
2022-04-14T18:54:07,150 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,158 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,165 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,168 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:07,168 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:54:09,362 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,372 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2257
2022-04-14T18:54:09,372 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2257
2022-04-14T18:54:09,373 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,373 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,373 [INFO ] W-9011-vgg_1.0 TS_METRICS - W-9011-vgg_1.0.ms:3716|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,374 [INFO ] W-9011-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:135|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,388 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,398 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,400 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2286
2022-04-14T18:54:09,400 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2286
2022-04-14T18:54:09,401 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,401 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,401 [INFO ] W-9014-vgg_1.0 TS_METRICS - W-9014-vgg_1.0.ms:3744|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,401 [INFO ] W-9014-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:126|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,405 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,406 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291
2022-04-14T18:54:09,406 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291
2022-04-14T18:54:09,406 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,406 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,406 [INFO ] W-9003-vgg_1.0 TS_METRICS - W-9003-vgg_1.0.ms:3752|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,407 [INFO ] W-9003-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:139|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,415 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2301
2022-04-14T18:54:09,415 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2301
2022-04-14T18:54:09,418 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,418 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,418 [INFO ] W-9001-vgg_1.0 TS_METRICS - W-9001-vgg_1.0.ms:3764|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,418 [INFO ] W-9001-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:141|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,443 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,444 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2329
2022-04-14T18:54:09,444 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2329
2022-04-14T18:54:09,444 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,444 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,444 [INFO ] W-9007-vgg_1.0 TS_METRICS - W-9007-vgg_1.0.ms:3789|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,445 [INFO ] W-9007-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:123|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,447 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,448 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2334
2022-04-14T18:54:09,448 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2334
2022-04-14T18:54:09,448 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,448 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,448 [INFO ] W-9010-vgg_1.0 TS_METRICS - W-9010-vgg_1.0.ms:3792|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,448 [INFO ] W-9010-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:137|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,450 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,451 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,451 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2338
2022-04-14T18:54:09,451 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2338
2022-04-14T18:54:09,452 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,452 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,452 [INFO ] W-9002-vgg_1.0 TS_METRICS - W-9002-vgg_1.0.ms:3798|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,452 [INFO ] W-9002-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:124|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,452 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2328
2022-04-14T18:54:09,452 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2328
2022-04-14T18:54:09,452 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,452 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,452 [INFO ] W-9008-vgg_1.0 TS_METRICS - W-9008-vgg_1.0.ms:3797|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,453 [INFO ] W-9008-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:149|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,456 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,459 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2277
2022-04-14T18:54:09,459 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2277
2022-04-14T18:54:09,459 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,459 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,459 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,459 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2344
2022-04-14T18:54:09,459 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2344
2022-04-14T18:54:09,459 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,459 [INFO ] W-9004-vgg_1.0 TS_METRICS - W-9004-vgg_1.0.ms:3805|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,459 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,459 [INFO ] W-9004-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:57|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,459 [INFO ] W-9009-vgg_1.0 TS_METRICS - W-9009-vgg_1.0.ms:3803|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,460 [INFO ] W-9009-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:98|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,477 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,480 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2322
2022-04-14T18:54:09,480 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2322
2022-04-14T18:54:09,480 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,480 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,480 [INFO ] W-9006-vgg_1.0 TS_METRICS - W-9006-vgg_1.0.ms:3825|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,481 [INFO ] W-9006-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:52|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,495 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,495 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2327
2022-04-14T18:54:09,495 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2327
2022-04-14T18:54:09,496 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,496 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,496 [INFO ] W-9005-vgg_1.0 TS_METRICS - W-9005-vgg_1.0.ms:3842|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,496 [INFO ] W-9005-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:47|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,504 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,505 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2390
2022-04-14T18:54:09,505 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2390
2022-04-14T18:54:09,505 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,505 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,505 [INFO ] W-9015-vgg_1.0 TS_METRICS - W-9015-vgg_1.0.ms:3832|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,505 [INFO ] W-9015-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:47|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,514 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,515 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2394
2022-04-14T18:54:09,515 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2394
2022-04-14T18:54:09,515 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,515 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,515 [INFO ] W-9013-vgg_1.0 TS_METRICS - W-9013-vgg_1.0.ms:3858|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,516 [INFO ] W-9013-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:145|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,519 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,520 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2341
2022-04-14T18:54:09,520 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2341
2022-04-14T18:54:09,521 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,521 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,521 [INFO ] W-9000-vgg_1.0 TS_METRICS - W-9000-vgg_1.0.ms:3870|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,521 [INFO ] W-9000-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:55|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:09,524 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:54:09,524 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2340
2022-04-14T18:54:09,524 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2340
2022-04-14T18:54:09,524 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,524 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:54:09,524 [INFO ] W-9012-vgg_1.0 TS_METRICS - W-9012-vgg_1.0.ms:3867|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984049
2022-04-14T18:54:09,525 [INFO ] W-9012-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:52|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:25,528 [INFO ] epollEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:60248 "GET /models HTTP/1.1" 200 12
2022-04-14T18:54:25,529 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:38,460 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984078460
2022-04-14T18:54:38,460 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984078460
2022-04-14T18:54:38,463 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Backend received inference at: 1649984078
2022-04-14T18:54:38,496 [INFO ] W-9011-vgg_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:31.96|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:612e572d-191a-4cd9-8e31-ce4abd45859d,timestamp:1649984078
2022-04-14T18:54:38,497 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35
2022-04-14T18:54:38,497 [INFO ] W-9011-vgg_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:32.03|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:612e572d-191a-4cd9-8e31-ce4abd45859d,timestamp:1649984078
2022-04-14T18:54:38,497 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35
2022-04-14T18:54:38,497 [INFO ] W-9011-vgg_1.0 ACCESS_LOG - /127.0.0.1:50982 "PUT /predictions/vgg HTTP/1.1" 200 48
2022-04-14T18:54:38,498 [INFO ] W-9011-vgg_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:38,498 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 365560, Backend time ns: 37911451
2022-04-14T18:54:38,498 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 365560, Backend time ns: 37911451
2022-04-14T18:54:38,498 [INFO ] W-9011-vgg_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:54:38,498 [INFO ] W-9011-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:55:06,895 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:9.1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,896 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365348815917969|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,896 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.45859146118164|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,896 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,897 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60133.703125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,897 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3441.08203125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:55:06,897 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984106
2022-04-14T18:56:33,275 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T18:56:33,275 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T18:56:33,319 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T18:56:33,319 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T18:56:33,439 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414185551797-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T18:56:33,439 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414185551797-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T18:56:33,448 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414185551797-shutdown.cfg",
  "modelCount": 1,
  "created": 1649984151798,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T18:56:33,448 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414185551797-shutdown.cfg",
  "modelCount": 1,
  "created": 1649984151798,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T18:56:33,460 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414185551797-shutdown.cfg
2022-04-14T18:56:33,460 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414185551797-shutdown.cfg
2022-04-14T18:56:33,461 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414185551797-shutdown.cfg validated successfully
2022-04-14T18:56:33,461 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414185551797-shutdown.cfg validated successfully
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:56:34,233 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T18:56:34,233 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T18:56:34,233 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T18:56:34,234 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T18:56:34,234 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T18:56:34,271 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T18:56:34,270 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T18:56:34,271 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T18:56:34,270 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T18:56:34,270 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T18:56:34,271 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T18:56:34,272 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T18:56:34,272 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T18:56:34,272 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T18:56:34,271 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T18:56:34,272 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T18:56:34,272 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T18:56:34,272 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T18:56:34,272 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T18:56:34,271 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T18:56:34,271 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T18:56:34,272 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T18:56:34,272 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T18:56:34,272 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T18:56:34,272 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T18:56:34,272 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T18:56:34,272 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T18:56:34,270 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T18:56:34,272 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T18:56:34,272 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T18:56:34,272 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T18:56:34,272 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T18:56:34,272 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T18:56:34,272 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T18:56:34,272 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T18:56:34,272 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T18:56:34,279 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T18:56:34,272 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T18:56:34,279 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T18:56:34,788 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T18:56:34,788 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T18:56:34,794 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T18:56:34,794 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T18:56:34,819 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T18:56:34,819 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T18:56:34,820 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T18:56:34,820 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T18:56:34,822 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T18:56:34,822 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T18:56:35,407 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T18:56:35,407 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T18:56:35,458 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2022-04-14T18:56:35,459 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - [PID]25227
2022-04-14T18:56:35,460 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,460 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,461 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,461 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,468 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T18:56:35,468 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T18:56:35,492 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-04-14T18:56:35,494 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - [PID]25210
2022-04-14T18:56:35,494 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,494 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,494 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2022-04-14T18:56:35,494 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,495 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T18:56:35,495 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T18:56:35,495 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,495 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - [PID]25217
2022-04-14T18:56:35,496 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,496 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,496 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,497 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T18:56:35,497 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T18:56:35,497 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,509 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2022-04-14T18:56:35,510 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - [PID]25208
2022-04-14T18:56:35,510 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,506 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2022-04-14T18:56:35,510 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,510 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - [PID]25211
2022-04-14T18:56:35,511 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,511 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,511 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,511 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T18:56:35,511 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,511 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,511 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T18:56:35,511 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,511 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T18:56:35,511 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T18:56:35,517 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2022-04-14T18:56:35,519 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - [PID]25220
2022-04-14T18:56:35,519 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,519 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,519 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,521 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T18:56:35,519 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,521 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T18:56:35,523 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2022-04-14T18:56:35,525 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-04-14T18:56:35,524 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-04-14T18:56:35,525 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2022-04-14T18:56:35,525 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2022-04-14T18:56:35,525 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - [PID]25209
2022-04-14T18:56:35,526 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,526 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,526 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,527 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T18:56:35,527 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T18:56:35,526 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,537 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2022-04-14T18:56:35,540 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2022-04-14T18:56:35,541 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-04-14T18:56:35,542 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,542 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,543 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195543
2022-04-14T18:56:35,543 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195543
2022-04-14T18:56:35,542 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195542
2022-04-14T18:56:35,547 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2022-04-14T18:56:35,549 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:83.3|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,550 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - [PID]25219
2022-04-14T18:56:35,551 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,551 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365322113037109|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,551 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,551 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,551 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T18:56:35,551 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T18:56:35,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.4586181640625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:61823.95703125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,553 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1750.828125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,553 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.8|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984195
2022-04-14T18:56:35,556 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195556
2022-04-14T18:56:35,556 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2022-04-14T18:56:35,556 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195556
2022-04-14T18:56:35,582 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2022-04-14T18:56:35,583 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - [PID]25225
2022-04-14T18:56:35,583 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,583 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,583 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,584 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T18:56:35,584 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T18:56:35,583 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,591 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195591
2022-04-14T18:56:35,591 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2022-04-14T18:56:35,591 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195591
2022-04-14T18:56:35,612 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2022-04-14T18:56:35,612 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2022-04-14T18:56:35,624 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2022-04-14T18:56:35,625 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - [PID]25216
2022-04-14T18:56:35,625 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,625 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - [PID]25222
2022-04-14T18:56:35,625 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - [PID]25221
2022-04-14T18:56:35,625 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,625 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,625 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T18:56:35,625 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,625 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,625 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,625 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T18:56:35,626 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T18:56:35,626 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T18:56:35,626 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T18:56:35,626 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T18:56:35,626 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,659 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195659
2022-04-14T18:56:35,642 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2022-04-14T18:56:35,660 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2022-04-14T18:56:35,660 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,662 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - [PID]25212
2022-04-14T18:56:35,663 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,663 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,663 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,663 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,663 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T18:56:35,663 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T18:56:35,663 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,659 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195659
2022-04-14T18:56:35,660 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,660 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,659 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195659
2022-04-14T18:56:35,659 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195659
2022-04-14T18:56:35,665 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195665
2022-04-14T18:56:35,668 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195668
2022-04-14T18:56:35,661 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,665 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195665
2022-04-14T18:56:35,659 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2022-04-14T18:56:35,668 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195668
2022-04-14T18:56:35,668 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,658 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2022-04-14T18:56:35,666 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2022-04-14T18:56:35,668 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,669 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,676 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,694 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2022-04-14T18:56:35,695 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - [PID]25223
2022-04-14T18:56:35,695 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,696 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,696 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,696 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T18:56:35,696 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,696 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,696 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T18:56:35,696 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,698 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,709 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195709
2022-04-14T18:56:35,709 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195709
2022-04-14T18:56:35,709 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,712 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2022-04-14T18:56:35,732 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2022-04-14T18:56:35,733 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - [PID]25218
2022-04-14T18:56:35,734 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,734 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,734 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,734 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,735 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T18:56:35,735 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T18:56:35,744 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,761 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195761
2022-04-14T18:56:35,761 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195761
2022-04-14T18:56:35,762 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2022-04-14T18:56:35,785 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:35,803 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2022-04-14T18:56:35,804 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - [PID]25224
2022-04-14T18:56:35,804 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T18:56:35,805 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,805 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T18:56:35,805 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T18:56:35,805 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T18:56:35,805 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T18:56:35,821 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2022-04-14T18:56:35,821 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195821
2022-04-14T18:56:35,821 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984195821
2022-04-14T18:56:35,856 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T18:56:37,961 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:37,971 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2303
2022-04-14T18:56:37,971 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2303
2022-04-14T18:56:37,972 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,972 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,972 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:37,973 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2305
2022-04-14T18:56:37,973 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2305
2022-04-14T18:56:37,973 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,973 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,973 [INFO ] W-9001-vgg_1.0 TS_METRICS - W-9001-vgg_1.0.ms:3730|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984197
2022-04-14T18:56:37,974 [INFO ] W-9001-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:127|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:37,979 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:37,980 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2312
2022-04-14T18:56:37,980 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2312
2022-04-14T18:56:37,980 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,980 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,980 [INFO ] W-9011-vgg_1.0 TS_METRICS - W-9011-vgg_1.0.ms:3734|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984197
2022-04-14T18:56:37,980 [INFO ] W-9011-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:126|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:37,972 [INFO ] W-9000-vgg_1.0 TS_METRICS - W-9000-vgg_1.0.ms:3731|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984197
2022-04-14T18:56:37,982 [INFO ] W-9000-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:137|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:37,987 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:37,988 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326
2022-04-14T18:56:37,988 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326
2022-04-14T18:56:37,988 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,988 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:37,988 [INFO ] W-9004-vgg_1.0 TS_METRICS - W-9004-vgg_1.0.ms:3744|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984197
2022-04-14T18:56:37,988 [INFO ] W-9004-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:106|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:37,997 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,010 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,014 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2342
2022-04-14T18:56:38,014 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2342
2022-04-14T18:56:38,014 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,014 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,014 [INFO ] W-9003-vgg_1.0 TS_METRICS - W-9003-vgg_1.0.ms:3771|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,014 [INFO ] W-9003-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,019 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2359
2022-04-14T18:56:38,019 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2359
2022-04-14T18:56:38,020 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,020 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,020 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,020 [INFO ] W-9009-vgg_1.0 TS_METRICS - W-9009-vgg_1.0.ms:3775|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,020 [INFO ] W-9009-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:118|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,020 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,021 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2352
2022-04-14T18:56:38,021 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2352
2022-04-14T18:56:38,021 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,021 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,021 [INFO ] W-9005-vgg_1.0 TS_METRICS - W-9005-vgg_1.0.ms:3777|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,021 [INFO ] W-9005-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:127|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,023 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2362
2022-04-14T18:56:38,023 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2362
2022-04-14T18:56:38,023 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,023 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,023 [INFO ] W-9006-vgg_1.0 TS_METRICS - W-9006-vgg_1.0.ms:3779|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,024 [INFO ] W-9006-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:120|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,038 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,039 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2343
2022-04-14T18:56:38,039 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2343
2022-04-14T18:56:38,039 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,039 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,039 [INFO ] W-9012-vgg_1.0 TS_METRICS - W-9012-vgg_1.0.ms:3792|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,040 [INFO ] W-9012-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:29|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,063 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,063 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2347
2022-04-14T18:56:38,063 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2347
2022-04-14T18:56:38,063 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,063 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,063 [INFO ] W-9010-vgg_1.0 TS_METRICS - W-9010-vgg_1.0.ms:3817|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,064 [INFO ] W-9010-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:58|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,064 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,066 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2406
2022-04-14T18:56:38,066 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2406
2022-04-14T18:56:38,066 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,066 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,066 [INFO ] W-9008-vgg_1.0 TS_METRICS - W-9008-vgg_1.0.ms:3821|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,067 [INFO ] W-9008-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:70|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,067 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,068 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2371
2022-04-14T18:56:38,068 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2371
2022-04-14T18:56:38,068 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,068 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,068 [INFO ] W-9002-vgg_1.0 TS_METRICS - W-9002-vgg_1.0.ms:3825|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,068 [INFO ] W-9002-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:38|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,068 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,069 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2313
2022-04-14T18:56:38,069 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2313
2022-04-14T18:56:38,069 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,069 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,069 [INFO ] W-9013-vgg_1.0 TS_METRICS - W-9013-vgg_1.0.ms:3822|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,069 [INFO ] W-9013-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:47|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,075 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,076 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2379
2022-04-14T18:56:38,076 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2379
2022-04-14T18:56:38,076 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,076 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,076 [INFO ] W-9007-vgg_1.0 TS_METRICS - W-9007-vgg_1.0.ms:3832|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,077 [INFO ] W-9007-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:33|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,082 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,082 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2290
2022-04-14T18:56:38,082 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2290
2022-04-14T18:56:38,082 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,082 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,082 [INFO ] W-9015-vgg_1.0 TS_METRICS - W-9015-vgg_1.0.ms:3812|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,083 [INFO ] W-9015-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:31|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:38,111 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T18:56:38,111 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2239
2022-04-14T18:56:38,111 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2239
2022-04-14T18:56:38,111 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,111 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T18:56:38,112 [INFO ] W-9014-vgg_1.0 TS_METRICS - W-9014-vgg_1.0.ms:3842|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984198
2022-04-14T18:56:38,112 [INFO ] W-9014-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:52|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:55,900 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984215900
2022-04-14T18:56:55,900 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649984215900
2022-04-14T18:56:55,903 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Backend received inference at: 1649984215
2022-04-14T18:56:55,944 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 41
2022-04-14T18:56:55,943 [INFO ] W-9001-vgg_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:39.04|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:8a94d329-01fd-4c44-8314-5a43f502ad26,timestamp:1649984215
2022-04-14T18:56:55,944 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 41
2022-04-14T18:56:55,944 [INFO ] W-9001-vgg_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:39.14|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:8a94d329-01fd-4c44-8314-5a43f502ad26,timestamp:1649984215
2022-04-14T18:56:55,945 [INFO ] W-9001-vgg_1.0 ACCESS_LOG - /127.0.0.1:50986 "PUT /predictions/vgg HTTP/1.1" 200 54
2022-04-14T18:56:55,946 [INFO ] W-9001-vgg_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:55,946 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 201051, Backend time ns: 46391445
2022-04-14T18:56:55,946 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 201051, Backend time ns: 46391445
2022-04-14T18:56:55,946 [INFO ] W-9001-vgg_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:56:55,946 [INFO ] W-9001-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T18:57:35,437 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:14.3|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.365268707275391|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458671569824219|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:60151.94921875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3422.83203125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:57:35,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984255
2022-04-14T18:58:35,437 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,438 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365268707275391|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,439 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.458671569824219|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,439 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60155.453125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3419.328125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:58:35,439 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984315
2022-04-14T18:59:35,440 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,441 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365261077880859|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,441 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.45867919921875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,441 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,441 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60150.80859375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,442 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3423.95703125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T18:59:35,442 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984375
2022-04-14T19:00:35,442 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,442 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365261077880859|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,442 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.45867919921875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,443 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,443 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60150.53515625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,443 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3424.22265625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:00:35,443 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984435
2022-04-14T19:01:35,442 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,443 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365261077880859|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,443 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.45867919921875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,443 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,444 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60154.68359375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,444 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3420.0625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:01:35,444 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984495
2022-04-14T19:02:35,449 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:11.1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,449 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365257263183594|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,449 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.458683013916016|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,450 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,450 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60153.953125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,450 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3420.86328125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:02:35,450 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984555
2022-04-14T19:03:35,448 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,448 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365253448486328|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,449 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.458686828613281|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,449 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,449 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60153.58203125|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,449 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3421.171875|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:03:35,449 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984615
2022-04-14T19:04:35,456 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:11.1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,456 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:4.365253448486328|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,456 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:10.458686828613281|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,457 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,457 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:60152.22265625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,457 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:3422.52734375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:04:35,457 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:6.4|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649984675
2022-04-14T19:12:13,405 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T19:12:13,405 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-14T19:12:13,449 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T19:12:13,449 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-14T19:12:13,583 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414190450677-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T19:12:13,583 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /users/shaniyur/miniconda3/lib/python3.9/site-packages
Current directory: /users/shaniyur/BigDataProject5/Task_3
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 16
Max heap size: 16076 M
Python executable: /users/shaniyur/miniconda3/bin/python
Config file: logs/config/20220414190450677-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Initial Models: vgg=vgg.mar
Log dir: /users/shaniyur/BigDataProject5/Task_3/logs
Metrics dir: /users/shaniyur/BigDataProject5/Task_3/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 16
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /users/shaniyur/BigDataProject5/Task_3/model_store
Model config: N/A
2022-04-14T19:12:13,594 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414190450677-shutdown.cfg",
  "modelCount": 1,
  "created": 1649984690678,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T19:12:13,594 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220414190450677-shutdown.cfg",
  "modelCount": 1,
  "created": 1649984690678,
  "models": {
    "vgg": {
      "1.0": {
        "defaultVersion": true,
        "marName": "vgg.mar",
        "minWorkers": 16,
        "maxWorkers": 16,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-04-14T19:12:13,607 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414190450677-shutdown.cfg
2022-04-14T19:12:13,607 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220414190450677-shutdown.cfg
2022-04-14T19:12:13,608 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414190450677-shutdown.cfg validated successfully
2022-04-14T19:12:13,608 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220414190450677-shutdown.cfg validated successfully
2022-04-14T19:12:14,581 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T19:12:14,581 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model vgg
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model vgg
2022-04-14T19:12:14,582 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T19:12:14,582 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model vgg loaded.
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T19:12:14,582 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: vgg, count: 16
2022-04-14T19:12:14,620 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T19:12:14,620 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T19:12:14,619 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T19:12:14,619 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T19:12:14,620 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T19:12:14,620 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T19:12:14,620 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T19:12:14,620 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T19:12:14,620 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T19:12:14,620 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T19:12:14,620 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-04-14T19:12:14,620 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9014]
2022-04-14T19:12:14,620 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9009]
2022-04-14T19:12:14,620 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9010]
2022-04-14T19:12:14,619 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9003]
2022-04-14T19:12:14,621 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T19:12:14,620 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9005]
2022-04-14T19:12:14,621 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T19:12:14,621 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-04-14T19:12:14,621 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9004]
2022-04-14T19:12:14,620 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9008]
2022-04-14T19:12:14,622 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T19:12:14,620 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9012]
2022-04-14T19:12:14,619 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9013]
2022-04-14T19:12:14,622 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T19:12:14,621 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T19:12:14,620 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9011]
2022-04-14T19:12:14,620 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T19:12:14,622 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9015]
2022-04-14T19:12:14,620 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9007]
2022-04-14T19:12:14,622 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9002]
2022-04-14T19:12:14,621 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/users/shaniyur/miniconda3/bin/python, /users/shaniyur/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9006]
2022-04-14T19:12:14,623 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T19:12:14,623 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-04-14T19:12:15,081 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T19:12:15,081 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-14T19:12:15,081 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T19:12:15,081 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-04-14T19:12:15,102 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T19:12:15,102 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-14T19:12:15,103 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T19:12:15,103 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-04-14T19:12:15,104 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T19:12:15,104 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-14T19:12:15,691 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T19:12:15,691 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-14T19:12:15,751 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9009
2022-04-14T19:12:15,757 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - [PID]25687
2022-04-14T19:12:15,758 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,759 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,759 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,759 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,764 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-04-14T19:12:15,766 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - [PID]25686
2022-04-14T19:12:15,767 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T19:12:15,767 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,767 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,768 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,767 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9009
2022-04-14T19:12:15,767 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,769 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T19:12:15,769 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-04-14T19:12:15,773 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9012
2022-04-14T19:12:15,775 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - [PID]25706
2022-04-14T19:12:15,775 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,775 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,775 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,776 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T19:12:15,776 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,776 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9012
2022-04-14T19:12:15,791 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9015
2022-04-14T19:12:15,793 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9011
2022-04-14T19:12:15,793 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - [PID]25704
2022-04-14T19:12:15,794 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,794 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,794 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T19:12:15,794 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - [PID]25707
2022-04-14T19:12:15,794 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,794 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,794 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,795 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T19:12:15,795 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9011
2022-04-14T19:12:15,794 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,795 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,795 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,794 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9015
2022-04-14T19:12:15,803 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-04-14T19:12:15,803 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003
2022-04-14T19:12:15,805 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - [PID]25696
2022-04-14T19:12:15,805 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,805 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,805 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,805 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,805 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T19:12:15,805 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2022-04-14T19:12:15,809 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9012.
2022-04-14T19:12:15,811 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9009.
2022-04-14T19:12:15,812 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9011.
2022-04-14T19:12:15,816 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9015.
2022-04-14T19:12:15,817 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135817
2022-04-14T19:12:15,817 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135817
2022-04-14T19:12:15,820 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135820
2022-04-14T19:12:15,820 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135820
2022-04-14T19:12:15,820 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135820
2022-04-14T19:12:15,820 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135820
2022-04-14T19:12:15,820 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9005
2022-04-14T19:12:15,821 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - [PID]25703
2022-04-14T19:12:15,822 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135822
2022-04-14T19:12:15,822 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135822
2022-04-14T19:12:15,822 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.
2022-04-14T19:12:15,823 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,823 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135823
2022-04-14T19:12:15,823 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,824 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,823 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135823
2022-04-14T19:12:15,823 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,824 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T19:12:15,823 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002
2022-04-14T19:12:15,824 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9005
2022-04-14T19:12:15,825 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - [PID]25699
2022-04-14T19:12:15,825 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,825 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,825 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,825 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T19:12:15,825 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2022-04-14T19:12:15,825 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,848 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9010
2022-04-14T19:12:15,848 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:87.5|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,849 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:4.3652191162109375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,849 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - [PID]25705
2022-04-14T19:12:15,849 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,849 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,849 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135849
2022-04-14T19:12:15,849 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:10.458721160888672|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,849 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,849 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135849
2022-04-14T19:12:15,849 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T19:12:15,849 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,849 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9010
2022-04-14T19:12:15,853 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-04-14T19:12:15,855 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135855
2022-04-14T19:12:15,855 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135855
2022-04-14T19:12:15,855 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9005.
2022-04-14T19:12:15,850 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:70.6|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,856 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - [PID]25698
2022-04-14T19:12:15,856 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,856 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:61816.18359375|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,856 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,856 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,857 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T19:12:15,856 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,856 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.
2022-04-14T19:12:15,856 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1758.6015625|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,857 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-04-14T19:12:15,857 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:3.9|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985135
2022-04-14T19:12:15,858 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135858
2022-04-14T19:12:15,858 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135858
2022-04-14T19:12:15,889 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9010.
2022-04-14T19:12:15,890 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135890
2022-04-14T19:12:15,873 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9006
2022-04-14T19:12:15,890 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135890
2022-04-14T19:12:15,890 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - [PID]25700
2022-04-14T19:12:15,890 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135890
2022-04-14T19:12:15,889 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9013
2022-04-14T19:12:15,890 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135890
2022-04-14T19:12:15,872 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9014
2022-04-14T19:12:15,890 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,889 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9008
2022-04-14T19:12:15,890 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-04-14T19:12:15,890 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - [PID]25688
2022-04-14T19:12:15,890 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,890 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - [PID]25697
2022-04-14T19:12:15,890 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,902 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,902 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,914 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T19:12:15,902 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,902 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - [PID]25702
2022-04-14T19:12:15,902 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T19:12:15,914 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9013
2022-04-14T19:12:15,902 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9006
2022-04-14T19:12:15,914 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T19:12:15,914 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,914 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9014
2022-04-14T19:12:15,915 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,915 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,915 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,915 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T19:12:15,915 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9008
2022-04-14T19:12:15,915 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,948 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135947
2022-04-14T19:12:15,948 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135948
2022-04-14T19:12:15,948 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9006.
2022-04-14T19:12:15,948 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135947
2022-04-14T19:12:15,948 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9008.
2022-04-14T19:12:15,948 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135948
2022-04-14T19:12:15,948 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,948 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,953 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135953
2022-04-14T19:12:15,970 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135970
2022-04-14T19:12:15,948 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,970 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135970
2022-04-14T19:12:15,970 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,955 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,953 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985135953
2022-04-14T19:12:15,970 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9014.
2022-04-14T19:12:15,956 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,955 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,954 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9013.
2022-04-14T19:12:15,948 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,948 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,971 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,988 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:15,987 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9007
2022-04-14T19:12:15,993 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - [PID]25701
2022-04-14T19:12:15,994 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,994 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:15,994 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:15,994 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:15,994 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T19:12:15,994 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9007
2022-04-14T19:12:16,006 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:16,006 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:16,017 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985136017
2022-04-14T19:12:16,016 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9007.
2022-04-14T19:12:16,017 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985136017
2022-04-14T19:12:16,020 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:16,054 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:16,097 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9004
2022-04-14T19:12:16,098 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - [PID]25709
2022-04-14T19:12:16,099 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-14T19:12:16,099 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:16,099 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change null -> WORKER_STARTED
2022-04-14T19:12:16,099 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T19:12:16,099 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9004
2022-04-14T19:12:16,101 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-04-14T19:12:16,119 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985136119
2022-04-14T19:12:16,119 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9004.
2022-04-14T19:12:16,119 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985136119
2022-04-14T19:12:16,149 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - model_name: vgg, batchSize: 1
2022-04-14T19:12:18,226 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,236 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2248
2022-04-14T19:12:18,236 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2248
2022-04-14T19:12:18,237 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,237 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,237 [INFO ] W-9002-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,237 [INFO ] W-9000-vgg_1.0 TS_METRICS - W-9000-vgg_1.0.ms:3647|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,238 [INFO ] W-9000-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:100|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,240 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2268
2022-04-14T19:12:18,240 [INFO ] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2268
2022-04-14T19:12:18,241 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,241 [DEBUG] W-9002-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,241 [INFO ] W-9002-vgg_1.0 TS_METRICS - W-9002-vgg_1.0.ms:3649|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,241 [INFO ] W-9002-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:115|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,254 [INFO ] W-9005-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,255 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2284
2022-04-14T19:12:18,255 [INFO ] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2284
2022-04-14T19:12:18,255 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,255 [DEBUG] W-9005-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,255 [INFO ] W-9005-vgg_1.0 TS_METRICS - W-9005-vgg_1.0.ms:3662|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,257 [INFO ] W-9005-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:118|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,281 [INFO ] W-9013-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,284 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2278
2022-04-14T19:12:18,284 [INFO ] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2278
2022-04-14T19:12:18,285 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,285 [DEBUG] W-9013-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,285 [INFO ] W-9013-vgg_1.0 TS_METRICS - W-9013-vgg_1.0.ms:3689|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,285 [INFO ] W-9013-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:54|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,292 [INFO ] W-9001-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,295 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2324
2022-04-14T19:12:18,295 [INFO ] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2324
2022-04-14T19:12:18,296 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,296 [DEBUG] W-9001-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,296 [INFO ] W-9001-vgg_1.0 TS_METRICS - W-9001-vgg_1.0.ms:3704|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,296 [INFO ] W-9001-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:155|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,299 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2292
2022-04-14T19:12:18,298 [INFO ] W-9006-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,299 [INFO ] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2292
2022-04-14T19:12:18,299 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,299 [DEBUG] W-9006-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,299 [INFO ] W-9006-vgg_1.0 TS_METRICS - W-9006-vgg_1.0.ms:3706|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,300 [INFO ] W-9006-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,311 [INFO ] W-9009-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,312 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2339
2022-04-14T19:12:18,312 [INFO ] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2339
2022-04-14T19:12:18,312 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,312 [DEBUG] W-9009-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,312 [INFO ] W-9009-vgg_1.0 TS_METRICS - W-9009-vgg_1.0.ms:3717|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,313 [INFO ] W-9009-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:154|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,319 [INFO ] W-9012-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,323 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2350
2022-04-14T19:12:18,323 [INFO ] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2350
2022-04-14T19:12:18,323 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,323 [DEBUG] W-9012-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,323 [INFO ] W-9012-vgg_1.0 TS_METRICS - W-9012-vgg_1.0.ms:3727|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,323 [INFO ] W-9012-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:153|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,335 [INFO ] W-9011-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,335 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2365
2022-04-14T19:12:18,335 [INFO ] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2365
2022-04-14T19:12:18,336 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,336 [DEBUG] W-9011-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,336 [INFO ] W-9011-vgg_1.0 TS_METRICS - W-9011-vgg_1.0.ms:3741|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,336 [INFO ] W-9011-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:149|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,337 [INFO ] W-9003-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,338 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2368
2022-04-14T19:12:18,338 [INFO ] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2368
2022-04-14T19:12:18,338 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,338 [DEBUG] W-9003-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,339 [INFO ] W-9003-vgg_1.0 TS_METRICS - W-9003-vgg_1.0.ms:3746|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,339 [INFO ] W-9003-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:148|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,371 [INFO ] W-9014-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,372 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2360
2022-04-14T19:12:18,372 [INFO ] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2360
2022-04-14T19:12:18,372 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,372 [DEBUG] W-9014-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,372 [INFO ] W-9014-vgg_1.0 TS_METRICS - W-9014-vgg_1.0.ms:3776|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,373 [INFO ] W-9014-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:43|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,392 [INFO ] W-9008-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,395 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2406
2022-04-14T19:12:18,395 [INFO ] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2406
2022-04-14T19:12:18,396 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,396 [DEBUG] W-9008-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,396 [INFO ] W-9008-vgg_1.0 TS_METRICS - W-9008-vgg_1.0.ms:3802|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,396 [INFO ] W-9008-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,399 [INFO ] W-9010-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,399 [INFO ] W-9007-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,399 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429
2022-04-14T19:12:18,399 [INFO ] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429
2022-04-14T19:12:18,400 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,400 [DEBUG] W-9010-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,400 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2332
2022-04-14T19:12:18,400 [INFO ] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2332
2022-04-14T19:12:18,400 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,400 [INFO ] W-9010-vgg_1.0 TS_METRICS - W-9010-vgg_1.0.ms:3805|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,400 [DEBUG] W-9007-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,400 [INFO ] W-9010-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:81|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,400 [INFO ] W-9007-vgg_1.0 TS_METRICS - W-9007-vgg_1.0.ms:3806|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,401 [INFO ] W-9007-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:52|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,405 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2229
2022-04-14T19:12:18,405 [INFO ] W-9004-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,405 [INFO ] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2229
2022-04-14T19:12:18,405 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,405 [DEBUG] W-9004-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,405 [INFO ] W-9004-vgg_1.0 TS_METRICS - W-9004-vgg_1.0.ms:3812|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,406 [INFO ] W-9004-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:58|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:18,407 [INFO ] W-9015-vgg_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-04-14T19:12:18,407 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2435
2022-04-14T19:12:18,407 [INFO ] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2435
2022-04-14T19:12:18,407 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,407 [DEBUG] W-9015-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-vgg_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-14T19:12:18,407 [INFO ] W-9015-vgg_1.0 TS_METRICS - W-9015-vgg_1.0.ms:3789|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:1649985138
2022-04-14T19:12:18,407 [INFO ] W-9015-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:123|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:27,494 [INFO ] epollEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:60270 "GET /models HTTP/1.1" 200 5
2022-04-14T19:12:27,495 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:39,357 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985159357
2022-04-14T19:12:39,357 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1649985159357
2022-04-14T19:12:39,360 [INFO ] W-9000-vgg_1.0-stdout MODEL_LOG - Backend received inference at: 1649985159
2022-04-14T19:12:39,399 [INFO ] W-9000-vgg_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:37.7|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:a8222da7-8837-4751-ba6a-6365b996ebc6,timestamp:1649985159
2022-04-14T19:12:39,400 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 41
2022-04-14T19:12:39,400 [INFO ] W-9000-vgg_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 41
2022-04-14T19:12:39,400 [INFO ] W-9000-vgg_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:37.81|#ModelName:vgg,Level:Model|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,requestID:a8222da7-8837-4751-ba6a-6365b996ebc6,timestamp:1649985159
2022-04-14T19:12:39,400 [INFO ] W-9000-vgg_1.0 ACCESS_LOG - /127.0.0.1:51004 "PUT /predictions/vgg HTTP/1.1" 200 51
2022-04-14T19:12:39,401 [INFO ] W-9000-vgg_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:39,401 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 331043, Backend time ns: 44324474
2022-04-14T19:12:39,401 [DEBUG] W-9000-vgg_1.0 org.pytorch.serve.job.Job - Waiting time ns: 331043, Backend time ns: 44324474
2022-04-14T19:12:39,401 [INFO ] W-9000-vgg_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
2022-04-14T19:12:39,401 [INFO ] W-9000-vgg_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:node0.grp14-a5.ut-cs378-s22-pg0.utah.cloudlab.us,timestamp:null
